{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from collections import Counter\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ChrisThomasTravels</td>\n",
       "      <td>Ossining, NY</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Initially the black sands of Canggu Beach are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Cherie H</td>\n",
       "      <td>Roumazieres-Loubert, France</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Unfortunately this gorgeou beach was covered i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Anastasia B</td>\n",
       "      <td>6 contributions</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Canggu Beach was wonderful and exactly what I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Therese Herlihy</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>We knew this was not a white sandy beach but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Mark Jones</td>\n",
       "      <td>Lake Macquarie, Australia</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Always find you will get a wave at Canggu (and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name                      Country      Date  \\\n",
       "0  ChrisThomasTravels                 Ossining, NY  Dec 2019   \n",
       "1            Cherie H  Roumazieres-Loubert, France  Dec 2019   \n",
       "2         Anastasia B              6 contributions  Jul 2019   \n",
       "3     Therese Herlihy              Dublin, Ireland  Dec 2019   \n",
       "4          Mark Jones    Lake Macquarie, Australia  Sep 2019   \n",
       "\n",
       "                                             Content  \n",
       "0  Initially the black sands of Canggu Beach are ...  \n",
       "1  Unfortunately this gorgeou beach was covered i...  \n",
       "2  Canggu Beach was wonderful and exactly what I ...  \n",
       "3  We knew this was not a white sandy beach but t...  \n",
       "4  Always find you will get a wave at Canggu (and...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "df=pd.read_csv('nusadua_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>case_folded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Initially the black sands of Canggu Beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Canggu Beach was wonderful and exactly what I ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>We knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Always find you will get a wave at Canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu (and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "0  Dec 2019  Initially the black sands of Canggu Beach are ...   \n",
       "1  Dec 2019  Unfortunately this gorgeou beach was covered i...   \n",
       "2  Jul 2019  Canggu Beach was wonderful and exactly what I ...   \n",
       "3  Dec 2019  We knew this was not a white sandy beach but t...   \n",
       "4  Sep 2019  Always find you will get a wave at Canggu (and...   \n",
       "\n",
       "                                         case_folded  \n",
       "0  initially the black sands of canggu beach are ...  \n",
       "1  unfortunately this gorgeou beach was covered i...  \n",
       "2  canggu beach was wonderful and exactly what i ...  \n",
       "3  we knew this was not a white sandy beach but t...  \n",
       "4  always find you will get a wave at canggu (and...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#case folding\n",
    "df['case_folded'] = df['Content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "# df['case_folded'].head()\n",
    "df.drop([\"Name\", \"Country\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emoticon/emoji removal\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "df['no_emot'] = df['case_folded'].apply(lambda x: remove_emoji(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>case_folded</th>\n",
       "      <th>no_emot</th>\n",
       "      <th>no_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Initially the black sands of Canggu Beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Canggu Beach was wonderful and exactly what I ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>We knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Always find you will get a wave at Canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "0  Dec 2019  Initially the black sands of Canggu Beach are ...   \n",
       "1  Dec 2019  Unfortunately this gorgeou beach was covered i...   \n",
       "2  Jul 2019  Canggu Beach was wonderful and exactly what I ...   \n",
       "3  Dec 2019  We knew this was not a white sandy beach but t...   \n",
       "4  Sep 2019  Always find you will get a wave at Canggu (and...   \n",
       "\n",
       "                                         case_folded  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu (and...   \n",
       "\n",
       "                                             no_emot  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu (and...   \n",
       "\n",
       "                                            no_punct  \n",
       "0  initially the black sands of canggu beach are ...  \n",
       "1  unfortunately this gorgeou beach was covered i...  \n",
       "2  canggu beach was wonderful and exactly what i ...  \n",
       "3  we knew this was not a white sandy beach but t...  \n",
       "4  always find you will get a wave at canggu and ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove punctuation\n",
    "x = 'everyne walking arounf had no masks on, i seem...'\n",
    "# re.sub(r'[^\\w ]+', \"\", x)\n",
    "\n",
    "df['no_punct'] = df['no_emot'].apply(lambda x: re.sub(r'[^\\w ]+', \"\", x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>case_folded</th>\n",
       "      <th>no_emot</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>no_freq_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Initially the black sands of Canggu Beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially black sands canggu are quite novel a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou was covered rubbish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Canggu Beach was wonderful and exactly what I ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu was wonderful exactly what i wanted my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>We knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not white sandy but itself ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Always find you will get a wave at Canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu and ...</td>\n",
       "      <td>always find will get wave at canggu surrounds ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "0  Dec 2019  Initially the black sands of Canggu Beach are ...   \n",
       "1  Dec 2019  Unfortunately this gorgeou beach was covered i...   \n",
       "2  Jul 2019  Canggu Beach was wonderful and exactly what I ...   \n",
       "3  Dec 2019  We knew this was not a white sandy beach but t...   \n",
       "4  Sep 2019  Always find you will get a wave at Canggu (and...   \n",
       "\n",
       "                                         case_folded  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu (and...   \n",
       "\n",
       "                                             no_emot  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu (and...   \n",
       "\n",
       "                                            no_punct  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu and ...   \n",
       "\n",
       "                                       no_freq_words  \n",
       "0  initially black sands canggu are quite novel a...  \n",
       "1  unfortunately this gorgeou was covered rubbish...  \n",
       "2  canggu was wonderful exactly what i wanted my ...  \n",
       "3  we knew this was not white sandy but itself ha...  \n",
       "4  always find will get wave at canggu surrounds ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequent words removal\n",
    "# text = ' '.join(df['no_punct'])\n",
    "# text = text.split()\n",
    "\n",
    "# freq_words = pd.Series(text).value_counts()\n",
    "# f20 = freq_words[:20]\n",
    "# f20\n",
    "\n",
    "# df['no_fr_words'] = df['no_punct'].apply(lambda x: ' '.join([t for t in x.split() if t not in f20]))\n",
    "\n",
    "cnt = Counter()\n",
    "for text in df[\"no_punct\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "# cnt.most_common(10)\n",
    "\n",
    "FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\n",
    "def remove_freqwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n",
    "\n",
    "df[\"no_freq_words\"] = df[\"no_punct\"].apply(lambda text: remove_freqwords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>case_folded</th>\n",
       "      <th>no_emot</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>no_freq_words</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Initially the black sands of Canggu Beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially black sands canggu are quite novel a...</td>\n",
       "      <td>initially black sands canggu quite novel spot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou was covered rubbish...</td>\n",
       "      <td>unfortunately gorgeou covered rubbish little f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Canggu Beach was wonderful and exactly what I ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu was wonderful exactly what i wanted my ...</td>\n",
       "      <td>canggu wonderful exactly wanted vacation spent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>We knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not white sandy but itself ha...</td>\n",
       "      <td>knew white sandy lots rubbish noisy lots drunk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Always find you will get a wave at Canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu and ...</td>\n",
       "      <td>always find will get wave at canggu surrounds ...</td>\n",
       "      <td>always find will wave canggu surrounds without...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "0  Dec 2019  Initially the black sands of Canggu Beach are ...   \n",
       "1  Dec 2019  Unfortunately this gorgeou beach was covered i...   \n",
       "2  Jul 2019  Canggu Beach was wonderful and exactly what I ...   \n",
       "3  Dec 2019  We knew this was not a white sandy beach but t...   \n",
       "4  Sep 2019  Always find you will get a wave at Canggu (and...   \n",
       "\n",
       "                                         case_folded  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu (and...   \n",
       "\n",
       "                                             no_emot  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu (and...   \n",
       "\n",
       "                                            no_punct  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu and ...   \n",
       "\n",
       "                                       no_freq_words  \\\n",
       "0  initially black sands canggu are quite novel a...   \n",
       "1  unfortunately this gorgeou was covered rubbish...   \n",
       "2  canggu was wonderful exactly what i wanted my ...   \n",
       "3  we knew this was not white sandy but itself ha...   \n",
       "4  always find will get wave at canggu surrounds ...   \n",
       "\n",
       "                                        no_stopwords  \n",
       "0  initially black sands canggu quite novel spot ...  \n",
       "1  unfortunately gorgeou covered rubbish little f...  \n",
       "2  canggu wonderful exactly wanted vacation spent...  \n",
       "3  knew white sandy lots rubbish noisy lots drunk...  \n",
       "4  always find will wave canggu surrounds without...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stopwords Removal\n",
    "stop = set(stopwords.words('english'))\n",
    "# df['no_stopwords'] = df['no_fr_words'].apply(lambda x: ' '.join([t for t in x.split() if t not in stopwords]))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df[\"no_stopwords\"] = df[\"no_freq_words\"].apply(lambda text: remove_stopwords(text))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>case_folded</th>\n",
       "      <th>no_emot</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>no_freq_words</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>no_rare_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Initially the black sands of Canggu Beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially black sands canggu are quite novel a...</td>\n",
       "      <td>initially black sands canggu quite novel spot ...</td>\n",
       "      <td>initially black sands canggu quite novel spot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou was covered rubbish...</td>\n",
       "      <td>unfortunately gorgeou covered rubbish little f...</td>\n",
       "      <td>unfortunately gorgeou covered rubbish little f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Canggu Beach was wonderful and exactly what I ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu was wonderful exactly what i wanted my ...</td>\n",
       "      <td>canggu wonderful exactly wanted vacation spent...</td>\n",
       "      <td>canggu wonderful exactly wanted vacation spent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>We knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not white sandy but itself ha...</td>\n",
       "      <td>knew white sandy lots rubbish noisy lots drunk...</td>\n",
       "      <td>knew white sandy lots rubbish noisy lots drunk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Always find you will get a wave at Canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu and ...</td>\n",
       "      <td>always find will get wave at canggu surrounds ...</td>\n",
       "      <td>always find will wave canggu surrounds without...</td>\n",
       "      <td>always find will wave canggu surrounds without...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "0  Dec 2019  Initially the black sands of Canggu Beach are ...   \n",
       "1  Dec 2019  Unfortunately this gorgeou beach was covered i...   \n",
       "2  Jul 2019  Canggu Beach was wonderful and exactly what I ...   \n",
       "3  Dec 2019  We knew this was not a white sandy beach but t...   \n",
       "4  Sep 2019  Always find you will get a wave at Canggu (and...   \n",
       "\n",
       "                                         case_folded  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu (and...   \n",
       "\n",
       "                                             no_emot  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu (and...   \n",
       "\n",
       "                                            no_punct  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu and ...   \n",
       "\n",
       "                                       no_freq_words  \\\n",
       "0  initially black sands canggu are quite novel a...   \n",
       "1  unfortunately this gorgeou was covered rubbish...   \n",
       "2  canggu was wonderful exactly what i wanted my ...   \n",
       "3  we knew this was not white sandy but itself ha...   \n",
       "4  always find will get wave at canggu surrounds ...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  initially black sands canggu quite novel spot ...   \n",
       "1  unfortunately gorgeou covered rubbish little f...   \n",
       "2  canggu wonderful exactly wanted vacation spent...   \n",
       "3  knew white sandy lots rubbish noisy lots drunk...   \n",
       "4  always find will wave canggu surrounds without...   \n",
       "\n",
       "                                       no_rare_words  \n",
       "0  initially black sands canggu quite novel spot ...  \n",
       "1  unfortunately gorgeou covered rubbish little f...  \n",
       "2  canggu wonderful exactly wanted vacation spent...  \n",
       "3  knew white sandy lots rubbish noisy lots drunk...  \n",
       "4  always find will wave canggu surrounds without...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rare words removal\n",
    "# rare20 = most_common.tail(20)\n",
    "# df['no_rare_words'] = df['no_stopwords'].apply(lambda x : ' '.join([t for t in x.split() if t not in rare20]))\n",
    "\n",
    "n_rare_words = 10\n",
    "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "def remove_rarewords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n",
    "\n",
    "df[\"no_rare_words\"] = df[\"no_stopwords\"].apply(lambda text: remove_rarewords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>case_folded</th>\n",
       "      <th>no_emot</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>no_freq_words</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>no_rare_words</th>\n",
       "      <th>text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Initially the black sands of Canggu Beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially black sands canggu are quite novel a...</td>\n",
       "      <td>initially black sands canggu quite novel spot ...</td>\n",
       "      <td>initially black sands canggu quite novel spot ...</td>\n",
       "      <td>initi black sand canggu quit novel spot becom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou was covered rubbish...</td>\n",
       "      <td>unfortunately gorgeou covered rubbish little f...</td>\n",
       "      <td>unfortunately gorgeou covered rubbish little f...</td>\n",
       "      <td>unfortun gorgeou cover rubbish littl food drin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Canggu Beach was wonderful and exactly what I ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu was wonderful exactly what i wanted my ...</td>\n",
       "      <td>canggu wonderful exactly wanted vacation spent...</td>\n",
       "      <td>canggu wonderful exactly wanted vacation spent...</td>\n",
       "      <td>canggu wonder exactli want vacat spent three w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>We knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not white sandy but itself ha...</td>\n",
       "      <td>knew white sandy lots rubbish noisy lots drunk...</td>\n",
       "      <td>knew white sandy lots rubbish noisy lots drunk...</td>\n",
       "      <td>knew white sandi lot rubbish noisi lot drunk p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Always find you will get a wave at Canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu and ...</td>\n",
       "      <td>always find will get wave at canggu surrounds ...</td>\n",
       "      <td>always find will wave canggu surrounds without...</td>\n",
       "      <td>always find will wave canggu surrounds without...</td>\n",
       "      <td>alway find will wave canggu surround without m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "0  Dec 2019  Initially the black sands of Canggu Beach are ...   \n",
       "1  Dec 2019  Unfortunately this gorgeou beach was covered i...   \n",
       "2  Jul 2019  Canggu Beach was wonderful and exactly what I ...   \n",
       "3  Dec 2019  We knew this was not a white sandy beach but t...   \n",
       "4  Sep 2019  Always find you will get a wave at Canggu (and...   \n",
       "\n",
       "                                         case_folded  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu (and...   \n",
       "\n",
       "                                             no_emot  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu (and...   \n",
       "\n",
       "                                            no_punct  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu and ...   \n",
       "\n",
       "                                       no_freq_words  \\\n",
       "0  initially black sands canggu are quite novel a...   \n",
       "1  unfortunately this gorgeou was covered rubbish...   \n",
       "2  canggu was wonderful exactly what i wanted my ...   \n",
       "3  we knew this was not white sandy but itself ha...   \n",
       "4  always find will get wave at canggu surrounds ...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  initially black sands canggu quite novel spot ...   \n",
       "1  unfortunately gorgeou covered rubbish little f...   \n",
       "2  canggu wonderful exactly wanted vacation spent...   \n",
       "3  knew white sandy lots rubbish noisy lots drunk...   \n",
       "4  always find will wave canggu surrounds without...   \n",
       "\n",
       "                                       no_rare_words  \\\n",
       "0  initially black sands canggu quite novel spot ...   \n",
       "1  unfortunately gorgeou covered rubbish little f...   \n",
       "2  canggu wonderful exactly wanted vacation spent...   \n",
       "3  knew white sandy lots rubbish noisy lots drunk...   \n",
       "4  always find will wave canggu surrounds without...   \n",
       "\n",
       "                                        text_stemmed  \n",
       "0  initi black sand canggu quit novel spot becom ...  \n",
       "1  unfortun gorgeou cover rubbish littl food drin...  \n",
       "2  canggu wonder exactli want vacat spent three w...  \n",
       "3  knew white sandi lot rubbish noisi lot drunk p...  \n",
       "4  alway find will wave canggu surround without m...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "df[\"text_stemmed\"] = df[\"no_rare_words\"].apply(lambda text: stem_words(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>case_folded</th>\n",
       "      <th>no_emot</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>no_freq_words</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>no_rare_words</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Initially the black sands of Canggu Beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially the black sands of canggu beach are ...</td>\n",
       "      <td>initially black sands canggu are quite novel a...</td>\n",
       "      <td>initially black sands canggu quite novel spot ...</td>\n",
       "      <td>initially black sands canggu quite novel spot ...</td>\n",
       "      <td>initi black sand canggu quit novel spot becom ...</td>\n",
       "      <td>initially black sand canggu quite novel spot b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>Unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou beach was covered i...</td>\n",
       "      <td>unfortunately this gorgeou was covered rubbish...</td>\n",
       "      <td>unfortunately gorgeou covered rubbish little f...</td>\n",
       "      <td>unfortunately gorgeou covered rubbish little f...</td>\n",
       "      <td>unfortun gorgeou cover rubbish littl food drin...</td>\n",
       "      <td>unfortunately gorgeou cover rubbish little foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Canggu Beach was wonderful and exactly what I ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu beach was wonderful and exactly what i ...</td>\n",
       "      <td>canggu was wonderful exactly what i wanted my ...</td>\n",
       "      <td>canggu wonderful exactly wanted vacation spent...</td>\n",
       "      <td>canggu wonderful exactly wanted vacation spent...</td>\n",
       "      <td>canggu wonder exactli want vacat spent three w...</td>\n",
       "      <td>canggu wonderful exactly want vacation spend t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dec 2019</td>\n",
       "      <td>We knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not a white sandy beach but t...</td>\n",
       "      <td>we knew this was not white sandy but itself ha...</td>\n",
       "      <td>knew white sandy lots rubbish noisy lots drunk...</td>\n",
       "      <td>knew white sandy lots rubbish noisy lots drunk...</td>\n",
       "      <td>knew white sandi lot rubbish noisi lot drunk p...</td>\n",
       "      <td>know white sandy lot rubbish noisy lot drink p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Always find you will get a wave at Canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu (and...</td>\n",
       "      <td>always find you will get a wave at canggu and ...</td>\n",
       "      <td>always find will get wave at canggu surrounds ...</td>\n",
       "      <td>always find will wave canggu surrounds without...</td>\n",
       "      <td>always find will wave canggu surrounds without...</td>\n",
       "      <td>alway find will wave canggu surround without m...</td>\n",
       "      <td>always find will wave canggu surround without ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "0  Dec 2019  Initially the black sands of Canggu Beach are ...   \n",
       "1  Dec 2019  Unfortunately this gorgeou beach was covered i...   \n",
       "2  Jul 2019  Canggu Beach was wonderful and exactly what I ...   \n",
       "3  Dec 2019  We knew this was not a white sandy beach but t...   \n",
       "4  Sep 2019  Always find you will get a wave at Canggu (and...   \n",
       "\n",
       "                                         case_folded  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu (and...   \n",
       "\n",
       "                                             no_emot  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu (and...   \n",
       "\n",
       "                                            no_punct  \\\n",
       "0  initially the black sands of canggu beach are ...   \n",
       "1  unfortunately this gorgeou beach was covered i...   \n",
       "2  canggu beach was wonderful and exactly what i ...   \n",
       "3  we knew this was not a white sandy beach but t...   \n",
       "4  always find you will get a wave at canggu and ...   \n",
       "\n",
       "                                       no_freq_words  \\\n",
       "0  initially black sands canggu are quite novel a...   \n",
       "1  unfortunately this gorgeou was covered rubbish...   \n",
       "2  canggu was wonderful exactly what i wanted my ...   \n",
       "3  we knew this was not white sandy but itself ha...   \n",
       "4  always find will get wave at canggu surrounds ...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  initially black sands canggu quite novel spot ...   \n",
       "1  unfortunately gorgeou covered rubbish little f...   \n",
       "2  canggu wonderful exactly wanted vacation spent...   \n",
       "3  knew white sandy lots rubbish noisy lots drunk...   \n",
       "4  always find will wave canggu surrounds without...   \n",
       "\n",
       "                                       no_rare_words  \\\n",
       "0  initially black sands canggu quite novel spot ...   \n",
       "1  unfortunately gorgeou covered rubbish little f...   \n",
       "2  canggu wonderful exactly wanted vacation spent...   \n",
       "3  knew white sandy lots rubbish noisy lots drunk...   \n",
       "4  always find will wave canggu surrounds without...   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0  initi black sand canggu quit novel spot becom ...   \n",
       "1  unfortun gorgeou cover rubbish littl food drin...   \n",
       "2  canggu wonder exactli want vacat spent three w...   \n",
       "3  knew white sandi lot rubbish noisi lot drunk p...   \n",
       "4  alway find will wave canggu surround without m...   \n",
       "\n",
       "                                              review  \n",
       "0  initially black sand canggu quite novel spot b...  \n",
       "1  unfortunately gorgeou cover rubbish little foo...  \n",
       "2  canggu wonderful exactly want vacation spend t...  \n",
       "3  know white sandy lot rubbish noisy lot drink p...  \n",
       "4  always find will wave canggu surround without ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "def lemmatize_words(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "\n",
    "df[\"review\"] = df[\"no_rare_words\"].apply(lambda text: lemmatize_words(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>Sep 2017</td>\n",
       "      <td>Very dirty/littered but lovely location. Waves...</td>\n",
       "      <td>dirtylittered lovely location wavessurf pretty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Came to the beach of an evening with friends t...</td>\n",
       "      <td>come even friend drink watch sunset pretty pop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>522</td>\n",
       "      <td>Jun 2015</td>\n",
       "      <td>Canggu's a great place to come for surfing and...</td>\n",
       "      <td>canggus great place come surf hang especially ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>Aug 2019</td>\n",
       "      <td>I have always stayed in Legian this time I dec...</td>\n",
       "      <td>always stay legian time decide try different p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>433</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Great beach for a visit. Surf variable to suit...</td>\n",
       "      <td>great visit surf variable suit taste attention...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                            Content  \\\n",
       "249  Sep 2017  Very dirty/littered but lovely location. Waves...   \n",
       "35   Sep 2019  Came to the beach of an evening with friends t...   \n",
       "522  Jun 2015  Canggu's a great place to come for surfing and...   \n",
       "52   Aug 2019  I have always stayed in Legian this time I dec...   \n",
       "433  Apr 2016  Great beach for a visit. Surf variable to suit...   \n",
       "\n",
       "                                                review  \n",
       "249  dirtylittered lovely location wavessurf pretty...  \n",
       "35   come even friend drink watch sunset pretty pop...  \n",
       "522  canggus great place come surf hang especially ...  \n",
       "52   always stay legian time decide try different p...  \n",
       "433  great visit surf variable suit taste attention...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"case_folded\", \"no_emot\", \"no_punct\", \"no_freq_words\", \"no_stopwords\", \"no_rare_words\", \"text_stemmed\"], axis=1, inplace=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data labelling\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "# df = pd.read_csv('doublesix_lemmatized.csv', sep='\\t')\n",
    "# df.head()\n",
    "\n",
    "df['scores'] = df['review'].apply(lambda review: sid.polarity_scores(review))\n",
    "df['compound']  = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "df['sentiment'] = df['compound'].apply(lambda c: 'positive' if c >= 0 else 'negative')\n",
    "\n",
    "# df.sample(20)\n",
    "\n",
    "df.to_csv('nusadua_preprocessed.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
