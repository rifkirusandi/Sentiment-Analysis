{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from collections import Counter\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MADHURKJAIN</td>\n",
       "      <td>Vadodara, India</td>\n",
       "      <td>Oct 2019</td>\n",
       "      <td>Pristine white sandy beach. Ideal place to rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ind</td>\n",
       "      <td>England, UK</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Arrrrh the beach... this is one place we didn’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>PrestonGuild</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Once you go past Legian beach you are on Semin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Aslam_Sherif</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>Aug 2019</td>\n",
       "      <td>Seminyak beach is nice and clean. I found it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sandy Ta</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>May 2019</td>\n",
       "      <td>Purposely chose Seminyak beach of all places i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name               Country      Date  \\\n",
       "0   MADHURKJAIN       Vadodara, India  Oct 2019   \n",
       "1           ind           England, UK  Sep 2019   \n",
       "2  PrestonGuild        United Kingdom  Jul 2019   \n",
       "3  Aslam_Sherif            London, UK  Aug 2019   \n",
       "4      Sandy Ta  Singapore, Singapore  May 2019   \n",
       "\n",
       "                                             Content  \n",
       "0  Pristine white sandy beach. Ideal place to rel...  \n",
       "1  Arrrrh the beach... this is one place we didn’...  \n",
       "2  Once you go past Legian beach you are on Semin...  \n",
       "3  Seminyak beach is nice and clean. I found it s...  \n",
       "4  Purposely chose Seminyak beach of all places i...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "df=pd.read_csv('seminyak_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>case_folded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Oct 2019</td>\n",
       "      <td>Pristine white sandy beach. Ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach. ideal place to rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach... this is one place we didn’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Once you go past Legian beach you are on Semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Aug 2019</td>\n",
       "      <td>Seminyak beach is nice and clean. I found it s...</td>\n",
       "      <td>seminyak beach is nice and clean. i found it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>May 2019</td>\n",
       "      <td>Purposely chose Seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "0  Oct 2019  Pristine white sandy beach. Ideal place to rel...   \n",
       "1  Sep 2019  Arrrrh the beach... this is one place we didn’...   \n",
       "2  Jul 2019  Once you go past Legian beach you are on Semin...   \n",
       "3  Aug 2019  Seminyak beach is nice and clean. I found it s...   \n",
       "4  May 2019  Purposely chose Seminyak beach of all places i...   \n",
       "\n",
       "                                         case_folded  \n",
       "0  pristine white sandy beach. ideal place to rel...  \n",
       "1  arrrrh the beach... this is one place we didn’...  \n",
       "2  once you go past legian beach you are on semin...  \n",
       "3  seminyak beach is nice and clean. i found it s...  \n",
       "4  purposely chose seminyak beach of all places i...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#case folding\n",
    "df['case_folded'] = df['Content'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "# df['case_folded'].head()\n",
    "df.drop([\"Name\", \"Country\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emoticon/emoji removal\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "df['no_emot'] = df['case_folded'].apply(lambda x: remove_emoji(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>case_folded</th>\n",
       "      <th>no_emot</th>\n",
       "      <th>no_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Oct 2019</td>\n",
       "      <td>Pristine white sandy beach. Ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach. ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach. ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach ideal place to rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach this is one place we didnt li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Once you go past Legian beach you are on Semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Aug 2019</td>\n",
       "      <td>Seminyak beach is nice and clean. I found it s...</td>\n",
       "      <td>seminyak beach is nice and clean. i found it s...</td>\n",
       "      <td>seminyak beach is nice and clean. i found it s...</td>\n",
       "      <td>seminyak beach is nice and clean i found it so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>May 2019</td>\n",
       "      <td>Purposely chose Seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "0  Oct 2019  Pristine white sandy beach. Ideal place to rel...   \n",
       "1  Sep 2019  Arrrrh the beach... this is one place we didn’...   \n",
       "2  Jul 2019  Once you go past Legian beach you are on Semin...   \n",
       "3  Aug 2019  Seminyak beach is nice and clean. I found it s...   \n",
       "4  May 2019  Purposely chose Seminyak beach of all places i...   \n",
       "\n",
       "                                         case_folded  \\\n",
       "0  pristine white sandy beach. ideal place to rel...   \n",
       "1  arrrrh the beach... this is one place we didn’...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean. i found it s...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                             no_emot  \\\n",
       "0  pristine white sandy beach. ideal place to rel...   \n",
       "1  arrrrh the beach... this is one place we didn’...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean. i found it s...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                            no_punct  \n",
       "0  pristine white sandy beach ideal place to rela...  \n",
       "1  arrrrh the beach this is one place we didnt li...  \n",
       "2  once you go past legian beach you are on semin...  \n",
       "3  seminyak beach is nice and clean i found it so...  \n",
       "4  purposely chose seminyak beach of all places i...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove punctuation\n",
    "x = 'everyne walking arounf had no masks on, i seem...'\n",
    "# re.sub(r'[^\\w ]+', \"\", x)\n",
    "\n",
    "df['no_punct'] = df['no_emot'].apply(lambda x: re.sub(r'[^\\w ]+', \"\", x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>case_folded</th>\n",
       "      <th>no_emot</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>no_freq_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Oct 2019</td>\n",
       "      <td>Pristine white sandy beach. Ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach. ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach. ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach ideal place to rela...</td>\n",
       "      <td>pristine white sandy ideal place relax or swim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach this is one place we didnt li...</td>\n",
       "      <td>arrrrh this one place we didnt list on our age...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Once you go past Legian beach you are on Semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once go past legian are on seminyak beachthere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Aug 2019</td>\n",
       "      <td>Seminyak beach is nice and clean. I found it s...</td>\n",
       "      <td>seminyak beach is nice and clean. i found it s...</td>\n",
       "      <td>seminyak beach is nice and clean. i found it s...</td>\n",
       "      <td>seminyak beach is nice and clean i found it so...</td>\n",
       "      <td>seminyak nice clean i found it some parts very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>May 2019</td>\n",
       "      <td>Purposely chose Seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak all places bali my tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "0  Oct 2019  Pristine white sandy beach. Ideal place to rel...   \n",
       "1  Sep 2019  Arrrrh the beach... this is one place we didn’...   \n",
       "2  Jul 2019  Once you go past Legian beach you are on Semin...   \n",
       "3  Aug 2019  Seminyak beach is nice and clean. I found it s...   \n",
       "4  May 2019  Purposely chose Seminyak beach of all places i...   \n",
       "\n",
       "                                         case_folded  \\\n",
       "0  pristine white sandy beach. ideal place to rel...   \n",
       "1  arrrrh the beach... this is one place we didn’...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean. i found it s...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                             no_emot  \\\n",
       "0  pristine white sandy beach. ideal place to rel...   \n",
       "1  arrrrh the beach... this is one place we didn’...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean. i found it s...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                            no_punct  \\\n",
       "0  pristine white sandy beach ideal place to rela...   \n",
       "1  arrrrh the beach this is one place we didnt li...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean i found it so...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                       no_freq_words  \n",
       "0  pristine white sandy ideal place relax or swim...  \n",
       "1  arrrrh this one place we didnt list on our age...  \n",
       "2  once go past legian are on seminyak beachthere...  \n",
       "3  seminyak nice clean i found it some parts very...  \n",
       "4  purposely chose seminyak all places bali my tr...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequent words removal\n",
    "# text = ' '.join(df['no_punct'])\n",
    "# text = text.split()\n",
    "\n",
    "# freq_words = pd.Series(text).value_counts()\n",
    "# f20 = freq_words[:20]\n",
    "# f20\n",
    "\n",
    "# df['no_fr_words'] = df['no_punct'].apply(lambda x: ' '.join([t for t in x.split() if t not in f20]))\n",
    "\n",
    "cnt = Counter()\n",
    "for text in df[\"no_punct\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "# cnt.most_common(10)\n",
    "\n",
    "FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\n",
    "def remove_freqwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n",
    "\n",
    "df[\"no_freq_words\"] = df[\"no_punct\"].apply(lambda text: remove_freqwords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>case_folded</th>\n",
       "      <th>no_emot</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>no_freq_words</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Oct 2019</td>\n",
       "      <td>Pristine white sandy beach. Ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach. ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach. ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach ideal place to rela...</td>\n",
       "      <td>pristine white sandy ideal place relax or swim...</td>\n",
       "      <td>pristine white sandy ideal place relax swim lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach this is one place we didnt li...</td>\n",
       "      <td>arrrrh this one place we didnt list on our age...</td>\n",
       "      <td>arrrrh one place didnt list agenda planning tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Once you go past Legian beach you are on Semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once go past legian are on seminyak beachthere...</td>\n",
       "      <td>go past legian seminyak beachthere high end ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Aug 2019</td>\n",
       "      <td>Seminyak beach is nice and clean. I found it s...</td>\n",
       "      <td>seminyak beach is nice and clean. i found it s...</td>\n",
       "      <td>seminyak beach is nice and clean. i found it s...</td>\n",
       "      <td>seminyak beach is nice and clean i found it so...</td>\n",
       "      <td>seminyak nice clean i found it some parts very...</td>\n",
       "      <td>seminyak nice clean found parts busy loud part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>May 2019</td>\n",
       "      <td>Purposely chose Seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak all places bali my tr...</td>\n",
       "      <td>purposely chose seminyak places bali trip want...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "0  Oct 2019  Pristine white sandy beach. Ideal place to rel...   \n",
       "1  Sep 2019  Arrrrh the beach... this is one place we didn’...   \n",
       "2  Jul 2019  Once you go past Legian beach you are on Semin...   \n",
       "3  Aug 2019  Seminyak beach is nice and clean. I found it s...   \n",
       "4  May 2019  Purposely chose Seminyak beach of all places i...   \n",
       "\n",
       "                                         case_folded  \\\n",
       "0  pristine white sandy beach. ideal place to rel...   \n",
       "1  arrrrh the beach... this is one place we didn’...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean. i found it s...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                             no_emot  \\\n",
       "0  pristine white sandy beach. ideal place to rel...   \n",
       "1  arrrrh the beach... this is one place we didn’...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean. i found it s...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                            no_punct  \\\n",
       "0  pristine white sandy beach ideal place to rela...   \n",
       "1  arrrrh the beach this is one place we didnt li...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean i found it so...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                       no_freq_words  \\\n",
       "0  pristine white sandy ideal place relax or swim...   \n",
       "1  arrrrh this one place we didnt list on our age...   \n",
       "2  once go past legian are on seminyak beachthere...   \n",
       "3  seminyak nice clean i found it some parts very...   \n",
       "4  purposely chose seminyak all places bali my tr...   \n",
       "\n",
       "                                        no_stopwords  \n",
       "0  pristine white sandy ideal place relax swim lo...  \n",
       "1  arrrrh one place didnt list agenda planning tr...  \n",
       "2  go past legian seminyak beachthere high end ho...  \n",
       "3  seminyak nice clean found parts busy loud part...  \n",
       "4  purposely chose seminyak places bali trip want...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stopwords Removal\n",
    "stop = set(stopwords.words('english'))\n",
    "# df['no_stopwords'] = df['no_fr_words'].apply(lambda x: ' '.join([t for t in x.split() if t not in stopwords]))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df[\"no_stopwords\"] = df[\"no_freq_words\"].apply(lambda text: remove_stopwords(text))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>case_folded</th>\n",
       "      <th>no_emot</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>no_freq_words</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>no_rare_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Oct 2019</td>\n",
       "      <td>Pristine white sandy beach. Ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach. ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach. ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach ideal place to rela...</td>\n",
       "      <td>pristine white sandy ideal place relax or swim...</td>\n",
       "      <td>pristine white sandy ideal place relax swim lo...</td>\n",
       "      <td>pristine white sandy ideal place relax swim lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach this is one place we didnt li...</td>\n",
       "      <td>arrrrh this one place we didnt list on our age...</td>\n",
       "      <td>arrrrh one place didnt list agenda planning tr...</td>\n",
       "      <td>arrrrh one place didnt list agenda planning tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Once you go past Legian beach you are on Semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once go past legian are on seminyak beachthere...</td>\n",
       "      <td>go past legian seminyak beachthere high end ho...</td>\n",
       "      <td>go past legian seminyak beachthere high end ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Aug 2019</td>\n",
       "      <td>Seminyak beach is nice and clean. I found it s...</td>\n",
       "      <td>seminyak beach is nice and clean. i found it s...</td>\n",
       "      <td>seminyak beach is nice and clean. i found it s...</td>\n",
       "      <td>seminyak beach is nice and clean i found it so...</td>\n",
       "      <td>seminyak nice clean i found it some parts very...</td>\n",
       "      <td>seminyak nice clean found parts busy loud part...</td>\n",
       "      <td>seminyak nice clean found parts busy loud part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>May 2019</td>\n",
       "      <td>Purposely chose Seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak all places bali my tr...</td>\n",
       "      <td>purposely chose seminyak places bali trip want...</td>\n",
       "      <td>purposely chose seminyak places bali trip want...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "0  Oct 2019  Pristine white sandy beach. Ideal place to rel...   \n",
       "1  Sep 2019  Arrrrh the beach... this is one place we didn’...   \n",
       "2  Jul 2019  Once you go past Legian beach you are on Semin...   \n",
       "3  Aug 2019  Seminyak beach is nice and clean. I found it s...   \n",
       "4  May 2019  Purposely chose Seminyak beach of all places i...   \n",
       "\n",
       "                                         case_folded  \\\n",
       "0  pristine white sandy beach. ideal place to rel...   \n",
       "1  arrrrh the beach... this is one place we didn’...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean. i found it s...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                             no_emot  \\\n",
       "0  pristine white sandy beach. ideal place to rel...   \n",
       "1  arrrrh the beach... this is one place we didn’...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean. i found it s...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                            no_punct  \\\n",
       "0  pristine white sandy beach ideal place to rela...   \n",
       "1  arrrrh the beach this is one place we didnt li...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean i found it so...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                       no_freq_words  \\\n",
       "0  pristine white sandy ideal place relax or swim...   \n",
       "1  arrrrh this one place we didnt list on our age...   \n",
       "2  once go past legian are on seminyak beachthere...   \n",
       "3  seminyak nice clean i found it some parts very...   \n",
       "4  purposely chose seminyak all places bali my tr...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  pristine white sandy ideal place relax swim lo...   \n",
       "1  arrrrh one place didnt list agenda planning tr...   \n",
       "2  go past legian seminyak beachthere high end ho...   \n",
       "3  seminyak nice clean found parts busy loud part...   \n",
       "4  purposely chose seminyak places bali trip want...   \n",
       "\n",
       "                                       no_rare_words  \n",
       "0  pristine white sandy ideal place relax swim lo...  \n",
       "1  arrrrh one place didnt list agenda planning tr...  \n",
       "2  go past legian seminyak beachthere high end ho...  \n",
       "3  seminyak nice clean found parts busy loud part...  \n",
       "4  purposely chose seminyak places bali trip want...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rare words removal\n",
    "# rare20 = most_common.tail(20)\n",
    "# df['no_rare_words'] = df['no_stopwords'].apply(lambda x : ' '.join([t for t in x.split() if t not in rare20]))\n",
    "\n",
    "n_rare_words = 10\n",
    "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "def remove_rarewords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n",
    "\n",
    "df[\"no_rare_words\"] = df[\"no_stopwords\"].apply(lambda text: remove_rarewords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>case_folded</th>\n",
       "      <th>no_emot</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>no_freq_words</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>no_rare_words</th>\n",
       "      <th>text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Oct 2019</td>\n",
       "      <td>Pristine white sandy beach. Ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach. ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach. ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach ideal place to rela...</td>\n",
       "      <td>pristine white sandy ideal place relax or swim...</td>\n",
       "      <td>pristine white sandy ideal place relax swim lo...</td>\n",
       "      <td>pristine white sandy ideal place relax swim lo...</td>\n",
       "      <td>pristin white sandi ideal place relax swim loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach this is one place we didnt li...</td>\n",
       "      <td>arrrrh this one place we didnt list on our age...</td>\n",
       "      <td>arrrrh one place didnt list agenda planning tr...</td>\n",
       "      <td>arrrrh one place didnt list agenda planning tr...</td>\n",
       "      <td>arrrrh one place didnt list agenda plan trip p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Once you go past Legian beach you are on Semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once go past legian are on seminyak beachthere...</td>\n",
       "      <td>go past legian seminyak beachthere high end ho...</td>\n",
       "      <td>go past legian seminyak beachthere high end ho...</td>\n",
       "      <td>go past legian seminyak beachther high end hot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Aug 2019</td>\n",
       "      <td>Seminyak beach is nice and clean. I found it s...</td>\n",
       "      <td>seminyak beach is nice and clean. i found it s...</td>\n",
       "      <td>seminyak beach is nice and clean. i found it s...</td>\n",
       "      <td>seminyak beach is nice and clean i found it so...</td>\n",
       "      <td>seminyak nice clean i found it some parts very...</td>\n",
       "      <td>seminyak nice clean found parts busy loud part...</td>\n",
       "      <td>seminyak nice clean found parts busy loud part...</td>\n",
       "      <td>seminyak nice clean found part busi loud part ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>May 2019</td>\n",
       "      <td>Purposely chose Seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak all places bali my tr...</td>\n",
       "      <td>purposely chose seminyak places bali trip want...</td>\n",
       "      <td>purposely chose seminyak places bali trip want...</td>\n",
       "      <td>purpos chose seminyak place bali trip want lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "0  Oct 2019  Pristine white sandy beach. Ideal place to rel...   \n",
       "1  Sep 2019  Arrrrh the beach... this is one place we didn’...   \n",
       "2  Jul 2019  Once you go past Legian beach you are on Semin...   \n",
       "3  Aug 2019  Seminyak beach is nice and clean. I found it s...   \n",
       "4  May 2019  Purposely chose Seminyak beach of all places i...   \n",
       "\n",
       "                                         case_folded  \\\n",
       "0  pristine white sandy beach. ideal place to rel...   \n",
       "1  arrrrh the beach... this is one place we didn’...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean. i found it s...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                             no_emot  \\\n",
       "0  pristine white sandy beach. ideal place to rel...   \n",
       "1  arrrrh the beach... this is one place we didn’...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean. i found it s...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                            no_punct  \\\n",
       "0  pristine white sandy beach ideal place to rela...   \n",
       "1  arrrrh the beach this is one place we didnt li...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean i found it so...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                       no_freq_words  \\\n",
       "0  pristine white sandy ideal place relax or swim...   \n",
       "1  arrrrh this one place we didnt list on our age...   \n",
       "2  once go past legian are on seminyak beachthere...   \n",
       "3  seminyak nice clean i found it some parts very...   \n",
       "4  purposely chose seminyak all places bali my tr...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  pristine white sandy ideal place relax swim lo...   \n",
       "1  arrrrh one place didnt list agenda planning tr...   \n",
       "2  go past legian seminyak beachthere high end ho...   \n",
       "3  seminyak nice clean found parts busy loud part...   \n",
       "4  purposely chose seminyak places bali trip want...   \n",
       "\n",
       "                                       no_rare_words  \\\n",
       "0  pristine white sandy ideal place relax swim lo...   \n",
       "1  arrrrh one place didnt list agenda planning tr...   \n",
       "2  go past legian seminyak beachthere high end ho...   \n",
       "3  seminyak nice clean found parts busy loud part...   \n",
       "4  purposely chose seminyak places bali trip want...   \n",
       "\n",
       "                                        text_stemmed  \n",
       "0  pristin white sandi ideal place relax swim loc...  \n",
       "1  arrrrh one place didnt list agenda plan trip p...  \n",
       "2  go past legian seminyak beachther high end hot...  \n",
       "3  seminyak nice clean found part busi loud part ...  \n",
       "4  purpos chose seminyak place bali trip want lea...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "df[\"text_stemmed\"] = df[\"no_rare_words\"].apply(lambda text: stem_words(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>case_folded</th>\n",
       "      <th>no_emot</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>no_freq_words</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>no_rare_words</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Oct 2019</td>\n",
       "      <td>Pristine white sandy beach. Ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach. ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach. ideal place to rel...</td>\n",
       "      <td>pristine white sandy beach ideal place to rela...</td>\n",
       "      <td>pristine white sandy ideal place relax or swim...</td>\n",
       "      <td>pristine white sandy ideal place relax swim lo...</td>\n",
       "      <td>pristine white sandy ideal place relax swim lo...</td>\n",
       "      <td>pristin white sandi ideal place relax swim loc...</td>\n",
       "      <td>pristine white sandy ideal place relax swim lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach... this is one place we didn’...</td>\n",
       "      <td>arrrrh the beach this is one place we didnt li...</td>\n",
       "      <td>arrrrh this one place we didnt list on our age...</td>\n",
       "      <td>arrrrh one place didnt list agenda planning tr...</td>\n",
       "      <td>arrrrh one place didnt list agenda planning tr...</td>\n",
       "      <td>arrrrh one place didnt list agenda plan trip p...</td>\n",
       "      <td>arrrrh one place didnt list agenda plan trip p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Once you go past Legian beach you are on Semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once you go past legian beach you are on semin...</td>\n",
       "      <td>once go past legian are on seminyak beachthere...</td>\n",
       "      <td>go past legian seminyak beachthere high end ho...</td>\n",
       "      <td>go past legian seminyak beachthere high end ho...</td>\n",
       "      <td>go past legian seminyak beachther high end hot...</td>\n",
       "      <td>go past legian seminyak beachthere high end ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Aug 2019</td>\n",
       "      <td>Seminyak beach is nice and clean. I found it s...</td>\n",
       "      <td>seminyak beach is nice and clean. i found it s...</td>\n",
       "      <td>seminyak beach is nice and clean. i found it s...</td>\n",
       "      <td>seminyak beach is nice and clean i found it so...</td>\n",
       "      <td>seminyak nice clean i found it some parts very...</td>\n",
       "      <td>seminyak nice clean found parts busy loud part...</td>\n",
       "      <td>seminyak nice clean found parts busy loud part...</td>\n",
       "      <td>seminyak nice clean found part busi loud part ...</td>\n",
       "      <td>seminyak nice clean find part busy loud part q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>May 2019</td>\n",
       "      <td>Purposely chose Seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak beach of all places i...</td>\n",
       "      <td>purposely chose seminyak all places bali my tr...</td>\n",
       "      <td>purposely chose seminyak places bali trip want...</td>\n",
       "      <td>purposely chose seminyak places bali trip want...</td>\n",
       "      <td>purpos chose seminyak place bali trip want lea...</td>\n",
       "      <td>purposely chose seminyak place bali trip want ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "0  Oct 2019  Pristine white sandy beach. Ideal place to rel...   \n",
       "1  Sep 2019  Arrrrh the beach... this is one place we didn’...   \n",
       "2  Jul 2019  Once you go past Legian beach you are on Semin...   \n",
       "3  Aug 2019  Seminyak beach is nice and clean. I found it s...   \n",
       "4  May 2019  Purposely chose Seminyak beach of all places i...   \n",
       "\n",
       "                                         case_folded  \\\n",
       "0  pristine white sandy beach. ideal place to rel...   \n",
       "1  arrrrh the beach... this is one place we didn’...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean. i found it s...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                             no_emot  \\\n",
       "0  pristine white sandy beach. ideal place to rel...   \n",
       "1  arrrrh the beach... this is one place we didn’...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean. i found it s...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                            no_punct  \\\n",
       "0  pristine white sandy beach ideal place to rela...   \n",
       "1  arrrrh the beach this is one place we didnt li...   \n",
       "2  once you go past legian beach you are on semin...   \n",
       "3  seminyak beach is nice and clean i found it so...   \n",
       "4  purposely chose seminyak beach of all places i...   \n",
       "\n",
       "                                       no_freq_words  \\\n",
       "0  pristine white sandy ideal place relax or swim...   \n",
       "1  arrrrh this one place we didnt list on our age...   \n",
       "2  once go past legian are on seminyak beachthere...   \n",
       "3  seminyak nice clean i found it some parts very...   \n",
       "4  purposely chose seminyak all places bali my tr...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  pristine white sandy ideal place relax swim lo...   \n",
       "1  arrrrh one place didnt list agenda planning tr...   \n",
       "2  go past legian seminyak beachthere high end ho...   \n",
       "3  seminyak nice clean found parts busy loud part...   \n",
       "4  purposely chose seminyak places bali trip want...   \n",
       "\n",
       "                                       no_rare_words  \\\n",
       "0  pristine white sandy ideal place relax swim lo...   \n",
       "1  arrrrh one place didnt list agenda planning tr...   \n",
       "2  go past legian seminyak beachthere high end ho...   \n",
       "3  seminyak nice clean found parts busy loud part...   \n",
       "4  purposely chose seminyak places bali trip want...   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0  pristin white sandi ideal place relax swim loc...   \n",
       "1  arrrrh one place didnt list agenda plan trip p...   \n",
       "2  go past legian seminyak beachther high end hot...   \n",
       "3  seminyak nice clean found part busi loud part ...   \n",
       "4  purpos chose seminyak place bali trip want lea...   \n",
       "\n",
       "                                              review  \n",
       "0  pristine white sandy ideal place relax swim lo...  \n",
       "1  arrrrh one place didnt list agenda plan trip p...  \n",
       "2  go past legian seminyak beachthere high end ho...  \n",
       "3  seminyak nice clean find part busy loud part q...  \n",
       "4  purposely chose seminyak place bali trip want ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "def lemmatize_words(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "\n",
    "df[\"review\"] = df[\"no_rare_words\"].apply(lambda text: lemmatize_words(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2735</td>\n",
       "      <td>May 2016</td>\n",
       "      <td>Nice beach once you negotiate the right rate f...</td>\n",
       "      <td>nice negotiate right rate deck chair great day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>Jul 2016</td>\n",
       "      <td>This beach is not clean at all. The best beach...</td>\n",
       "      <td>clean best beach esperance wa whitsundays qld ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3744</td>\n",
       "      <td>Jan 2015</td>\n",
       "      <td>Apparently December is the Seminyak Beach, Tra...</td>\n",
       "      <td>apparently december seminyak trash expo annual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3854</td>\n",
       "      <td>Nov 2014</td>\n",
       "      <td>Beach was very clean and able to walk miles al...</td>\n",
       "      <td>clean able walk mile along need shoe flip flop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>635</td>\n",
       "      <td>Aug 2018</td>\n",
       "      <td>Perfect place to enjoy the sun, sand and the w...</td>\n",
       "      <td>perfect place enjoy sun sand weather go even 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                            Content  \\\n",
       "2735  May 2016  Nice beach once you negotiate the right rate f...   \n",
       "2580  Jul 2016  This beach is not clean at all. The best beach...   \n",
       "3744  Jan 2015  Apparently December is the Seminyak Beach, Tra...   \n",
       "3854  Nov 2014  Beach was very clean and able to walk miles al...   \n",
       "635   Aug 2018  Perfect place to enjoy the sun, sand and the w...   \n",
       "\n",
       "                                                 review  \n",
       "2735  nice negotiate right rate deck chair great day...  \n",
       "2580  clean best beach esperance wa whitsundays qld ...  \n",
       "3744  apparently december seminyak trash expo annual...  \n",
       "3854  clean able walk mile along need shoe flip flop...  \n",
       "635   perfect place enjoy sun sand weather go even 1...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"case_folded\", \"no_emot\", \"no_punct\", \"no_freq_words\", \"no_stopwords\", \"no_rare_words\", \"text_stemmed\"], axis=1, inplace=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data labelling\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "# df = pd.read_csv('doublesix_lemmatized.csv', sep='\\t')\n",
    "# df.head()\n",
    "\n",
    "df['scores'] = df['review'].apply(lambda review: sid.polarity_scores(review))\n",
    "df['compound']  = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "df['sentiment'] = df['compound'].apply(lambda c: '1' if c >= 0 else '0')\n",
    "\n",
    "# df.sample(20)\n",
    "\n",
    "df.to_csv('seminyak_preprocessed.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "df = pd.read_csv('dataset_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(np.random.randint(0.0,100.0,size=(10,1)),\n",
    "#               index=range(10,20),\n",
    "#               columns=['review'],\n",
    "#               dtype='str')\n",
    "corpus = df['review'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5811)\t0.10286300090343525\n",
      "  (0, 6644)\t0.22367809590360443\n",
      "  (0, 10952)\t0.09694992051264838\n",
      "  (0, 3975)\t0.2751462137393001\n",
      "  (0, 1601)\t0.255235627871483\n",
      "  (0, 8658)\t0.2751462137393001\n",
      "  (0, 6009)\t0.22891526502714843\n",
      "  (0, 7657)\t0.2261774893103979\n",
      "  (0, 14857)\t0.255235627871483\n",
      "  (0, 8756)\t0.255235627871483\n",
      "  (0, 9475)\t0.2634992676392385\n",
      "  (0, 2777)\t0.2391607183700504\n",
      "  (0, 3173)\t0.526998535278477\n",
      "  (0, 1041)\t0.255235627871483\n",
      "  (0, 2282)\t0.10040229023366344\n",
      "  (1, 14024)\t0.1412880865631301\n",
      "  (1, 9958)\t0.24440233826254834\n",
      "  (1, 11102)\t0.15960011042939204\n",
      "  (1, 12816)\t0.1881133441892455\n",
      "  (1, 6886)\t0.22258352055554814\n",
      "  (1, 10437)\t0.24559919752520354\n",
      "  (1, 1529)\t0.20372316423715034\n",
      "  (1, 10555)\t0.27437597389717383\n",
      "  (1, 4234)\t0.203599057996276\n",
      "  (1, 13374)\t0.13829346369981993\n",
      "  :\t:\n",
      "  (10632, 12136)\t0.21637347407168817\n",
      "  (10632, 8325)\t0.11707967582241233\n",
      "  (10632, 15354)\t0.10326914803105286\n",
      "  (10632, 5364)\t0.08956985714994037\n",
      "  (10632, 10608)\t0.08055901906027649\n",
      "  (10632, 9080)\t0.08441056706386445\n",
      "  (10632, 13631)\t0.12203076504052399\n",
      "  (10632, 4603)\t0.0894162221556323\n",
      "  (10632, 12765)\t0.07958330770071273\n",
      "  (10632, 6546)\t0.12292347491663685\n",
      "  (10632, 10307)\t0.16823993289293235\n",
      "  (10632, 4413)\t0.09799755464697539\n",
      "  (10632, 8995)\t0.22691328515749817\n",
      "  (10632, 4111)\t0.057084840811001035\n",
      "  (10632, 13676)\t0.11741740323632895\n",
      "  (10632, 12058)\t0.17466856262027328\n",
      "  (10632, 11421)\t0.08518791526632477\n",
      "  (10632, 8005)\t0.08506620468045419\n",
      "  (10632, 6238)\t0.04860196919058869\n",
      "  (10632, 1418)\t0.09043812610411657\n",
      "  (10632, 8314)\t0.0551687377337601\n",
      "  (10632, 15753)\t0.08888820514421528\n",
      "  (10632, 11285)\t0.1774750824138169\n",
      "  (10632, 15270)\t0.05475490638568087\n",
      "  (10632, 5811)\t0.13423882909917118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(stop_words='english')\n",
    "resp = vec.fit_transform(corpus)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '0000',\n",
       " '000400',\n",
       " '000idr',\n",
       " '000rp',\n",
       " '000s',\n",
       " '0045',\n",
       " '04',\n",
       " '0430',\n",
       " '05',\n",
       " '0500',\n",
       " '053',\n",
       " '0615',\n",
       " '0700',\n",
       " '085935102585',\n",
       " '0900',\n",
       " '0r',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10000',\n",
       " '100000',\n",
       " '1000000',\n",
       " '10000000',\n",
       " '100000010',\n",
       " '100000idr',\n",
       " '100000ir',\n",
       " '100000k',\n",
       " '100000rp',\n",
       " '1000us',\n",
       " '100150k',\n",
       " '100200',\n",
       " '100k',\n",
       " '100kthe',\n",
       " '100m',\n",
       " '100rupes',\n",
       " '1010',\n",
       " '1011',\n",
       " '1011am',\n",
       " '1015',\n",
       " '1020',\n",
       " '10216',\n",
       " '1030',\n",
       " '103011',\n",
       " '1030ish',\n",
       " '104f',\n",
       " '105000',\n",
       " '10am',\n",
       " '10am2pmthe',\n",
       " '10ft',\n",
       " '10k',\n",
       " '10km',\n",
       " '10kyes',\n",
       " '10min',\n",
       " '10mins',\n",
       " '10mt',\n",
       " '10nz',\n",
       " '10pm',\n",
       " '10pmheaps',\n",
       " '10pmsit',\n",
       " '10th',\n",
       " '10x',\n",
       " '11',\n",
       " '110',\n",
       " '11000',\n",
       " '1100000',\n",
       " '1100am',\n",
       " '1100pm',\n",
       " '110k',\n",
       " '1110',\n",
       " '112',\n",
       " '115',\n",
       " '11am',\n",
       " '11k',\n",
       " '11pm',\n",
       " '11th',\n",
       " '12',\n",
       " '120',\n",
       " '120us',\n",
       " '121230',\n",
       " '122pm',\n",
       " '1230',\n",
       " '1230pm',\n",
       " '12km',\n",
       " '12nn330pm',\n",
       " '12pm',\n",
       " '12thfeb',\n",
       " '13',\n",
       " '1300',\n",
       " '1310',\n",
       " '137',\n",
       " '14',\n",
       " '1400',\n",
       " '140000',\n",
       " '1400000',\n",
       " '14a',\n",
       " '14km',\n",
       " '14kms',\n",
       " '14th',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '15000',\n",
       " '150000',\n",
       " '150000ir',\n",
       " '150000rp',\n",
       " '15000surf',\n",
       " '150250000',\n",
       " '150600',\n",
       " '150k',\n",
       " '152',\n",
       " '1520',\n",
       " '1520mins',\n",
       " '15first',\n",
       " '15hour',\n",
       " '15hours',\n",
       " '15k',\n",
       " '15km',\n",
       " '15m',\n",
       " '15min',\n",
       " '15minits',\n",
       " '15mins',\n",
       " '15minute',\n",
       " '16',\n",
       " '1600',\n",
       " '16000',\n",
       " '16bed',\n",
       " '16th',\n",
       " '17',\n",
       " '170',\n",
       " '1700',\n",
       " '1715pm',\n",
       " '1730',\n",
       " '174',\n",
       " '177m',\n",
       " '17h',\n",
       " '18',\n",
       " '180',\n",
       " '1800',\n",
       " '180000',\n",
       " '1815',\n",
       " '18hole',\n",
       " '18late',\n",
       " '18th',\n",
       " '19',\n",
       " '1900',\n",
       " '1900ish',\n",
       " '1922',\n",
       " '1960s',\n",
       " '1970s',\n",
       " '1974',\n",
       " '1976',\n",
       " '1980s',\n",
       " '1982',\n",
       " '1999',\n",
       " '19km',\n",
       " '1am',\n",
       " '1h',\n",
       " '1hour',\n",
       " '1hr',\n",
       " '1k',\n",
       " '1km',\n",
       " '1lhappy',\n",
       " '1m',\n",
       " '1mil',\n",
       " '1ml',\n",
       " '1personbumpy',\n",
       " '1pm',\n",
       " '1st',\n",
       " '1star',\n",
       " '1to',\n",
       " '1way',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '20000',\n",
       " '200000',\n",
       " '2000000',\n",
       " '200000for',\n",
       " '20000idr',\n",
       " '20000rph',\n",
       " '20000rup',\n",
       " '2000personcoconut',\n",
       " '2000rpi',\n",
       " '2000rpif',\n",
       " '2000s',\n",
       " '2002',\n",
       " '200300',\n",
       " '2004',\n",
       " '2005',\n",
       " '2005in',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009fast',\n",
       " '200idr',\n",
       " '200k',\n",
       " '200khour',\n",
       " '200m',\n",
       " '2010',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2016difficult',\n",
       " '2016fireworks',\n",
       " '2016i',\n",
       " '2016the',\n",
       " '2017',\n",
       " '2017the',\n",
       " '2017these',\n",
       " '2018',\n",
       " '2018saw',\n",
       " '2018the',\n",
       " '2019',\n",
       " '2019s',\n",
       " '2025k',\n",
       " '2025min',\n",
       " '2030',\n",
       " '2030min',\n",
       " '2030s',\n",
       " '2030usd',\n",
       " '2040',\n",
       " '20cents',\n",
       " '20drinks',\n",
       " '20idr',\n",
       " '20k',\n",
       " '20k30k',\n",
       " '20ks',\n",
       " '20mins',\n",
       " '20options',\n",
       " '20p',\n",
       " '20yrs',\n",
       " '21',\n",
       " '2127',\n",
       " '21st',\n",
       " '22',\n",
       " '228',\n",
       " '23',\n",
       " '23000',\n",
       " '23042015',\n",
       " '23also',\n",
       " '24',\n",
       " '240pm',\n",
       " '247',\n",
       " '24xweek',\n",
       " '25',\n",
       " '250',\n",
       " '2500',\n",
       " '25000',\n",
       " '250000',\n",
       " '2500000',\n",
       " '25000000',\n",
       " '250000person',\n",
       " '25000rp',\n",
       " '250aud',\n",
       " '250k',\n",
       " '250regardless',\n",
       " '250rp',\n",
       " '2527',\n",
       " '2530',\n",
       " '2530000',\n",
       " '2530k',\n",
       " '25aud',\n",
       " '25c',\n",
       " '25k',\n",
       " '25meters',\n",
       " '25p',\n",
       " '25th',\n",
       " '25tidak',\n",
       " '25yo',\n",
       " '26000',\n",
       " '26c',\n",
       " '270',\n",
       " '2712',\n",
       " '2729',\n",
       " '27th',\n",
       " '28',\n",
       " '287km',\n",
       " '28pp',\n",
       " '29',\n",
       " '2aud',\n",
       " '2bed',\n",
       " '2h',\n",
       " '2hour',\n",
       " '2hours',\n",
       " '2hr',\n",
       " '2hrs',\n",
       " '2ish',\n",
       " '2k',\n",
       " '2kids',\n",
       " '2km',\n",
       " '2long',\n",
       " '2m',\n",
       " '2min',\n",
       " '2minutes',\n",
       " '2nd',\n",
       " '2nights',\n",
       " '2pax',\n",
       " '2pm',\n",
       " '2the',\n",
       " '2weeks',\n",
       " '2wheeled',\n",
       " '2yr',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30000',\n",
       " '300000',\n",
       " '30000i',\n",
       " '30000idr',\n",
       " '30000idrperson',\n",
       " '30000rpi',\n",
       " '300500mgets',\n",
       " '300916',\n",
       " '300k',\n",
       " '300m',\n",
       " '300yds',\n",
       " '3035',\n",
       " '3040',\n",
       " '3040min',\n",
       " '3045',\n",
       " '30k',\n",
       " '30klunch',\n",
       " '30m',\n",
       " '30min',\n",
       " '30mins',\n",
       " '30minutes',\n",
       " '30ooo',\n",
       " '30pm',\n",
       " '30th',\n",
       " '32',\n",
       " '32c',\n",
       " '33',\n",
       " '330',\n",
       " '33000',\n",
       " '330pm',\n",
       " '338',\n",
       " '34',\n",
       " '34pm',\n",
       " '34times',\n",
       " '35',\n",
       " '350',\n",
       " '3500',\n",
       " '35000',\n",
       " '350000',\n",
       " '350k',\n",
       " '350m',\n",
       " '350rps',\n",
       " '354',\n",
       " '3540',\n",
       " '35min',\n",
       " '360',\n",
       " '363500',\n",
       " '365000',\n",
       " '38',\n",
       " '39000',\n",
       " '3am',\n",
       " '3but',\n",
       " '3d4n',\n",
       " '3hours',\n",
       " '3k',\n",
       " '3km',\n",
       " '3mile',\n",
       " '3minute',\n",
       " '3pm',\n",
       " '3rd',\n",
       " '3sides',\n",
       " '3x',\n",
       " '3year',\n",
       " '3yo',\n",
       " '3yrs',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '40000',\n",
       " '400000',\n",
       " '40005000',\n",
       " '400irp',\n",
       " '400k',\n",
       " '400m',\n",
       " '400mt',\n",
       " '4045',\n",
       " '40c',\n",
       " '40k',\n",
       " '40m',\n",
       " '40mins',\n",
       " '40us',\n",
       " '43',\n",
       " '430',\n",
       " '430500',\n",
       " '4305ish',\n",
       " '430pm',\n",
       " '445pm',\n",
       " '45',\n",
       " '450k',\n",
       " '4560',\n",
       " '45min',\n",
       " '45min1h',\n",
       " '45mins',\n",
       " '45pm',\n",
       " '4am',\n",
       " '4km',\n",
       " '4not',\n",
       " '4pm',\n",
       " '4r',\n",
       " '4stars',\n",
       " '4th',\n",
       " '4wd',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '50000',\n",
       " '500000',\n",
       " '500000rup',\n",
       " '50000200000',\n",
       " '50000idr',\n",
       " '50000r',\n",
       " '50000rememberyou',\n",
       " '50000rp',\n",
       " '50000rpa',\n",
       " '50000rph',\n",
       " '5000person',\n",
       " '5000rp',\n",
       " '5000rph',\n",
       " '5000rpperson',\n",
       " '5000rupiah',\n",
       " '500aud',\n",
       " '500ft',\n",
       " '500k',\n",
       " '500m',\n",
       " '500ml',\n",
       " '500pm',\n",
       " '50100k',\n",
       " '5075',\n",
       " '50c',\n",
       " '50ft',\n",
       " '50i',\n",
       " '50k',\n",
       " '50k100k',\n",
       " '50krp',\n",
       " '50m',\n",
       " '50min',\n",
       " '50p',\n",
       " '50th',\n",
       " '51',\n",
       " '510',\n",
       " '515',\n",
       " '530',\n",
       " '530am',\n",
       " '530pm',\n",
       " '545pm',\n",
       " '55',\n",
       " '550am',\n",
       " '550k',\n",
       " '56',\n",
       " '561',\n",
       " '56km',\n",
       " '57',\n",
       " '57mins',\n",
       " '58',\n",
       " '58mins',\n",
       " '5am',\n",
       " '5aud',\n",
       " '5aus',\n",
       " '5ft',\n",
       " '5heir',\n",
       " '5hotelalso',\n",
       " '5k',\n",
       " '5km',\n",
       " '5min',\n",
       " '5mins',\n",
       " '5minute',\n",
       " '5only',\n",
       " '5pm',\n",
       " '5pn',\n",
       " '5star',\n",
       " '5stars',\n",
       " '5th',\n",
       " '5times',\n",
       " '5us',\n",
       " '5x',\n",
       " '60',\n",
       " '600',\n",
       " '600000',\n",
       " '600pm',\n",
       " '6085usd',\n",
       " '60cm',\n",
       " '610',\n",
       " '615',\n",
       " '62',\n",
       " '620',\n",
       " '6281',\n",
       " '6281236906663',\n",
       " '6281999529816',\n",
       " '6282247810789jl',\n",
       " '6285252539612',\n",
       " '630700pm',\n",
       " '630am',\n",
       " '630ish',\n",
       " '630pm',\n",
       " '650',\n",
       " '650000',\n",
       " '66',\n",
       " '6630pm',\n",
       " '67',\n",
       " '68',\n",
       " '68ft',\n",
       " '6am',\n",
       " '6km',\n",
       " '6month',\n",
       " '6pm',\n",
       " '6pmthe',\n",
       " '6pmwe',\n",
       " '6ppl',\n",
       " '6r',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '7000',\n",
       " '70000',\n",
       " '70000if',\n",
       " '70100',\n",
       " '707',\n",
       " '70k',\n",
       " '710',\n",
       " '710h',\n",
       " '714mm',\n",
       " '730',\n",
       " '7303',\n",
       " '735',\n",
       " '7471',\n",
       " '75',\n",
       " '750k',\n",
       " '75m',\n",
       " '77f',\n",
       " '79firstly',\n",
       " '7am',\n",
       " '7am8am',\n",
       " '7aud',\n",
       " '7pm',\n",
       " '7pmthe',\n",
       " '80',\n",
       " '800',\n",
       " '80000',\n",
       " '800000',\n",
       " '800am',\n",
       " '800m',\n",
       " '800pm',\n",
       " '80361hibachi',\n",
       " '80aud',\n",
       " '80k',\n",
       " '81',\n",
       " '810',\n",
       " '81238014543',\n",
       " '818',\n",
       " '81933051669',\n",
       " '81999040601his',\n",
       " '830',\n",
       " '8301030am',\n",
       " '8309',\n",
       " '830am',\n",
       " '845',\n",
       " '85238655766',\n",
       " '8am',\n",
       " '8aud',\n",
       " '8happy',\n",
       " '8km',\n",
       " '8pm',\n",
       " '8years',\n",
       " '8yr',\n",
       " '90',\n",
       " '900',\n",
       " '900am',\n",
       " '90degree',\n",
       " '90f',\n",
       " '90k',\n",
       " '90there',\n",
       " '90us',\n",
       " '925',\n",
       " '92k',\n",
       " '930',\n",
       " '930am',\n",
       " '98',\n",
       " '99',\n",
       " '9am',\n",
       " '9km',\n",
       " '9pm',\n",
       " '9th',\n",
       " '_i',\n",
       " 'a10',\n",
       " 'a100',\n",
       " 'a20',\n",
       " 'aaa',\n",
       " 'aaah',\n",
       " 'aback',\n",
       " 'abandon',\n",
       " 'abas',\n",
       " 'abc',\n",
       " 'abeautiful',\n",
       " 'abide',\n",
       " 'ability',\n",
       " 'abit',\n",
       " 'able',\n",
       " 'abnormally',\n",
       " 'aboard',\n",
       " 'abort',\n",
       " 'abound',\n",
       " 'about130',\n",
       " 'aboutlots',\n",
       " 'aboutmarkets',\n",
       " 'aboutnot',\n",
       " 'aboutreally',\n",
       " 'aboutsome',\n",
       " 'aboutthe',\n",
       " 'abouttransportation',\n",
       " 'abovehighly',\n",
       " 'abovethe',\n",
       " 'abrasion',\n",
       " 'abrassion',\n",
       " 'abruptly',\n",
       " 'abselutely',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absoloutly',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutey',\n",
       " 'absolutley',\n",
       " 'absolutly',\n",
       " 'absorb',\n",
       " 'abstemiousaverage',\n",
       " 'absurd',\n",
       " 'abt',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abut',\n",
       " 'abuzz',\n",
       " 'abvoe',\n",
       " 'abysmal',\n",
       " 'ac',\n",
       " 'acapulco',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acces',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accessentry',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accessoriespaintingstoys',\n",
       " 'accessory',\n",
       " 'acciddent',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'acclaim',\n",
       " 'acclivity',\n",
       " 'accomadation',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accommodationplease',\n",
       " 'accomodating',\n",
       " 'accomodation',\n",
       " 'accomodations',\n",
       " 'accompanied',\n",
       " 'accompany',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'accordingly',\n",
       " 'accost',\n",
       " 'account',\n",
       " 'accountable',\n",
       " 'accoustic',\n",
       " 'accredited',\n",
       " 'accross',\n",
       " 'acctually',\n",
       " 'accumulate',\n",
       " 'accumulates',\n",
       " 'accumulation',\n",
       " 'accurate',\n",
       " 'ache',\n",
       " 'achieve',\n",
       " 'acivity',\n",
       " 'acknowledge',\n",
       " 'acnowledge',\n",
       " 'acompanied',\n",
       " 'acongs',\n",
       " 'acordinly',\n",
       " 'acorn',\n",
       " 'acoustic',\n",
       " 'acro',\n",
       " 'acrossit',\n",
       " 'acrross',\n",
       " 'act',\n",
       " 'acternoon',\n",
       " 'action',\n",
       " 'actitvities',\n",
       " 'activates',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'actives',\n",
       " 'activites',\n",
       " 'activitiesclose',\n",
       " 'activitiesdrinks',\n",
       " 'activitiesgreat',\n",
       " 'activitiesif',\n",
       " 'activitiesloved',\n",
       " 'activitiesthe',\n",
       " 'activitiesvisited',\n",
       " 'activitities',\n",
       " 'activity',\n",
       " 'activityi',\n",
       " 'activityit',\n",
       " 'activityour',\n",
       " 'activitythere',\n",
       " 'activityyou',\n",
       " 'actnot',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actuallybut',\n",
       " 'actualpriceworst',\n",
       " 'actualy',\n",
       " 'ad',\n",
       " 'adamant',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'addon',\n",
       " 'addpopular',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addressits',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adhoc',\n",
       " 'adi',\n",
       " 'adjacent',\n",
       " 'adjoin',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'administer',\n",
       " 'admire',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admittedly',\n",
       " 'adopt',\n",
       " 'adore',\n",
       " 'adorn',\n",
       " 'adoydya',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adter',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'adventurea',\n",
       " 'adventurebe',\n",
       " 'adventureit',\n",
       " 'adventureonly',\n",
       " 'adventurer',\n",
       " 'adventurous',\n",
       " 'adventurousenjoying',\n",
       " 'adventurousyou',\n",
       " 'advert',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'adviced',\n",
       " 'advies',\n",
       " 'advisable',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advises',\n",
       " 'advisor',\n",
       " 'advisory',\n",
       " 'advocate',\n",
       " 'aeria',\n",
       " 'aerial',\n",
       " 'aerobics',\n",
       " 'aeroplane',\n",
       " 'aesthetic',\n",
       " 'af',\n",
       " 'afar',\n",
       " 'afernoons',\n",
       " 'afetr',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'afflict',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'affords',\n",
       " 'afl',\n",
       " 'afloat',\n",
       " 'aforementioned',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'afro',\n",
       " 'afterall',\n",
       " 'afterbeach',\n",
       " 'afterglow',\n",
       " 'afteri',\n",
       " 'afternoon',\n",
       " 'afternoonbeach',\n",
       " 'afternoonenjoy',\n",
       " 'afternoonevening',\n",
       " 'afternoonevenings',\n",
       " 'afternooni',\n",
       " 'afternoonrelaxing',\n",
       " 'afternoonstay',\n",
       " 'afternoonthere',\n",
       " 'aftersunset',\n",
       " 'afterward',\n",
       " 'afther',\n",
       " 'againawful',\n",
       " 'againbalinese',\n",
       " 'againcertainly',\n",
       " 'againdouble',\n",
       " 'againjust',\n",
       " 'againnext',\n",
       " 'againnice',\n",
       " 'againpack',\n",
       " 'againps',\n",
       " 'againsee',\n",
       " 'againswimming',\n",
       " 'againtake',\n",
       " 'againthe',\n",
       " 'againwell',\n",
       " 'age',\n",
       " 'agegood',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agendaz',\n",
       " 'agent',\n",
       " 'agesmy',\n",
       " 'agesor',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'aggressivethe',\n",
       " 'aggrieve',\n",
       " 'agian',\n",
       " 'agile',\n",
       " 'agin',\n",
       " 'agitate',\n",
       " 'ago',\n",
       " 'agobut',\n",
       " 'agong',\n",
       " 'agood',\n",
       " 'agotourists',\n",
       " 'agourance',\n",
       " 'agowe',\n",
       " 'agreat',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agressive',\n",
       " 'agro',\n",
       " 'agung',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahhed',\n",
       " 'ahhhh',\n",
       " 'ahmazing',\n",
       " 'aid',\n",
       " 'aided',\n",
       " 'ailment',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'airasia',\n",
       " 'airbnb',\n",
       " 'airborne',\n",
       " 'airhead',\n",
       " 'airline',\n",
       " 'airlots',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airportit',\n",
       " 'airportits',\n",
       " 'airportnot',\n",
       " 'airporttake',\n",
       " 'airportwatching',\n",
       " 'airsofa',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alam',\n",
       " 'alang',\n",
       " 'alarm',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'albeit',\n",
       " 'albino',\n",
       " 'album',\n",
       " 'alcaraz',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'alcove',\n",
       " 'ale',\n",
       " 'alea',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alga',\n",
       " 'algae',\n",
       " 'algaein',\n",
       " 'algea',\n",
       " 'alienate',\n",
       " 'align',\n",
       " 'alignment',\n",
       " 'alike',\n",
       " 'alikepos',\n",
       " 'alila',\n",
       " 'alive',\n",
       " 'allah',\n",
       " 'allan',\n",
       " 'allawesome',\n",
       " 'allday',\n",
       " 'alley',\n",
       " 'alleyscertain',\n",
       " 'alleyway',\n",
       " 'allfood',\n",
       " 'alli',\n",
       " 'allif',\n",
       " 'allim',\n",
       " 'allin',\n",
       " 'allinclusive',\n",
       " 'allits',\n",
       " 'alliw',\n",
       " 'alll',\n",
       " 'alllove',\n",
       " 'allmanicured',\n",
       " 'allnever',\n",
       " 'allnight',\n",
       " 'allocate',\n",
       " 'allocated',\n",
       " 'allot',\n",
       " 'allover',\n",
       " 'allow',\n",
       " 'allowded',\n",
       " 'allower',\n",
       " 'allows',\n",
       " 'allright',\n",
       " 'alls',\n",
       " 'allshame',\n",
       " 'allsmells',\n",
       " 'allthat',\n",
       " 'allthe',\n",
       " 'allthough',\n",
       " 'alltraveled',\n",
       " 'allude',\n",
       " 'allvisited',\n",
       " 'allways',\n",
       " 'ally',\n",
       " 'almighty',\n",
       " 'alond',\n",
       " 'alonebeautiful',\n",
       " 'alongalso',\n",
       " 'alongbut',\n",
       " 'alongfor',\n",
       " 'alongloads',\n",
       " 'alonglots',\n",
       " 'alongside',\n",
       " 'alongthere',\n",
       " 'alongvfb',\n",
       " 'alongwith',\n",
       " 'alot',\n",
       " 'alouf',\n",
       " 'alright',\n",
       " 'alsoif',\n",
       " 'alsoits',\n",
       " 'alsomany',\n",
       " 'alsoprice',\n",
       " 'alsospecial',\n",
       " 'alsospend',\n",
       " 'alsowe',\n",
       " 'alsoyou',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alternativesall',\n",
       " 'altho',\n",
       " 'althought',\n",
       " 'altogether',\n",
       " 'altough',\n",
       " 'aluminium',\n",
       " 'alwaaaaays',\n",
       " 'alwats',\n",
       " 'alwaus',\n",
       " 'alway',\n",
       " 'am2',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17-Aug</td>\n",
       "      <td>Best American Cheese Burger with oldies milksh...</td>\n",
       "      <td>best american cheese burger oldie milkshake va...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.569, 'pos': 0.431, 'comp...</td>\n",
       "      <td>0.8908</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15-Dec</td>\n",
       "      <td>One of the beaches that are not full of touris...</td>\n",
       "      <td>one beach full tourist sure usually empty come...</td>\n",
       "      <td>{'neg': 0.053, 'neu': 0.534, 'pos': 0.412, 'co...</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12-Jul</td>\n",
       "      <td>the beach is clear and not so crowded, and als...</td>\n",
       "      <td>clear crowd people tide horse seller always bo...</td>\n",
       "      <td>{'neg': 0.218, 'neu': 0.545, 'pos': 0.236, 'co...</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14-Nov</td>\n",
       "      <td>Crowded beach but worth to be out there to cat...</td>\n",
       "      <td>crowd worth catch wave best time sunset totall...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.541, 'pos': 0.459, 'comp...</td>\n",
       "      <td>0.8797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>If you’re looking for the idyllic, white sand ...</td>\n",
       "      <td>youre look idyllic white sand turquoise blue w...</td>\n",
       "      <td>{'neg': 0.081, 'neu': 0.734, 'pos': 0.186, 'co...</td>\n",
       "      <td>0.5116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date                                            Content  \\\n",
       "0  17-Aug  Best American Cheese Burger with oldies milksh...   \n",
       "1  15-Dec  One of the beaches that are not full of touris...   \n",
       "2  12-Jul  the beach is clear and not so crowded, and als...   \n",
       "3  14-Nov  Crowded beach but worth to be out there to cat...   \n",
       "4  19-Dec  If you’re looking for the idyllic, white sand ...   \n",
       "\n",
       "                                              review  \\\n",
       "0  best american cheese burger oldie milkshake va...   \n",
       "1  one beach full tourist sure usually empty come...   \n",
       "2  clear crowd people tide horse seller always bo...   \n",
       "3  crowd worth catch wave best time sunset totall...   \n",
       "4  youre look idyllic white sand turquoise blue w...   \n",
       "\n",
       "                                              scores  compound  sentiment  \n",
       "0  {'neg': 0.0, 'neu': 0.569, 'pos': 0.431, 'comp...    0.8908          1  \n",
       "1  {'neg': 0.053, 'neu': 0.534, 'pos': 0.412, 'co...    0.9022          1  \n",
       "2  {'neg': 0.218, 'neu': 0.545, 'pos': 0.236, 'co...    0.0516          1  \n",
       "3  {'neg': 0.0, 'neu': 0.541, 'pos': 0.459, 'comp...    0.8797          1  \n",
       "4  {'neg': 0.081, 'neu': 0.734, 'pos': 0.186, 'co...    0.5116          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
