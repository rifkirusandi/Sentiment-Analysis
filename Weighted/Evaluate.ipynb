{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 390, 64)           1280064   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 389, 128)          16512     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 1,301,826\n",
      "Trainable params: 1,301,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('WeightedModel2\\\\tf_cnnmodel')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>16-Aug</td>\n",
       "      <td>We arrived to the beach around 4;30pm and the ...</td>\n",
       "      <td>arrive around 430pm buzzing pull beanbag drank...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.628, 'pos': 0.372, 'comp...</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1545</td>\n",
       "      <td>15-Nov</td>\n",
       "      <td>i love the seminyak beach...the sands...the co...</td>\n",
       "      <td>love seminyak beachthe sandsthe colourful plac...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'comp...</td>\n",
       "      <td>0.8591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1145</td>\n",
       "      <td>16-Mar</td>\n",
       "      <td>Fantastic beach. Cleaner after the Grand Hyatt...</td>\n",
       "      <td>fantastic clean grand hyatt unfortunately see ...</td>\n",
       "      <td>{'neg': 0.284, 'neu': 0.401, 'pos': 0.315, 'co...</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1693</td>\n",
       "      <td>16-Sep</td>\n",
       "      <td>Seminyak beach was always packed with tourists...</td>\n",
       "      <td>seminyak always pack tourist water cold hire c...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.616, 'pos': 0.384, 'comp...</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2048</td>\n",
       "      <td>17-May</td>\n",
       "      <td>Such a lovely beach to relax and watch the sun...</td>\n",
       "      <td>lovely relax watch sun go near busy kuta vibe ...</td>\n",
       "      <td>{'neg': 0.019, 'neu': 0.649, 'pos': 0.333, 'co...</td>\n",
       "      <td>0.9790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                            Content  \\\n",
       "1309  16-Aug  We arrived to the beach around 4;30pm and the ...   \n",
       "1545  15-Nov  i love the seminyak beach...the sands...the co...   \n",
       "1145  16-Mar  Fantastic beach. Cleaner after the Grand Hyatt...   \n",
       "1693  16-Sep  Seminyak beach was always packed with tourists...   \n",
       "2048  17-May  Such a lovely beach to relax and watch the sun...   \n",
       "\n",
       "                                                 review  \\\n",
       "1309  arrive around 430pm buzzing pull beanbag drank...   \n",
       "1545  love seminyak beachthe sandsthe colourful plac...   \n",
       "1145  fantastic clean grand hyatt unfortunately see ...   \n",
       "1693  seminyak always pack tourist water cold hire c...   \n",
       "2048  lovely relax watch sun go near busy kuta vibe ...   \n",
       "\n",
       "                                                 scores  compound  sentiment  \n",
       "1309  {'neg': 0.0, 'neu': 0.628, 'pos': 0.372, 'comp...    0.7964          1  \n",
       "1545  {'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'comp...    0.8591          1  \n",
       "1145  {'neg': 0.284, 'neu': 0.401, 'pos': 0.315, 'co...    0.2732          1  \n",
       "1693  {'neg': 0.0, 'neu': 0.616, 'pos': 0.384, 'comp...    0.6808          1  \n",
       "2048  {'neg': 0.019, 'neu': 0.649, 'pos': 0.333, 'co...    0.9790          1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('data_test.csv', converters={'reviews' : str})\n",
    "# test_data.drop([\"Date\", \"Content\"], axis=1, inplace=True)\n",
    "# test_data.fillna(0)\n",
    "# test_data = test_data.fillna(\"\")\n",
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    x_test  = np.array( tokenizer.texts_to_sequences(test_data['review'].tolist()) )\n",
    "    # x_test = tokenizer\n",
    "    x_test = pad_sequences(x_test, padding='post', maxlen=1210)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 390) for input KerasTensor(type_spec=TensorSpec(shape=(None, 390), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 1210).\n",
      "[[0.09216475 0.8810382 ]\n",
      " [0.05293751 0.928354  ]\n",
      " [0.06831741 0.90956306]\n",
      " ...\n",
      " [0.10228038 0.87140906]\n",
      " [0.6566642  0.34539357]\n",
      " [0.20985025 0.7640997 ]]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on test  data using `predict`\n",
    "print(\"Generate predictions for all samples\")\n",
    "predictions = new_model.predict(x_test)\n",
    "print(predictions)\n",
    "predict_results = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_sentiment'] = predict_results\n",
    "test_data['pred_sentiment'] = np.where((test_data.pred_sentiment == 0),'0',test_data.pred_sentiment)\n",
    "test_data['pred_sentiment'] = np.where((test_data.pred_sentiment == '1'),'1',test_data.pred_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.56      0.55       222\n",
      "           1       0.95      0.94      0.95      1905\n",
      "\n",
      "    accuracy                           0.90      2127\n",
      "   macro avg       0.74      0.75      0.75      2127\n",
      "weighted avg       0.91      0.90      0.90      2127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = ['0', '1']\n",
    "    \n",
    "print(classification_report(test_data['sentiment'].values.astype(int).astype(str),test_data['pred_sentiment'].values,labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0     1\n",
      "Actual              \n",
      "0          124    98\n",
      "1          107  1798\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(test_data['sentiment'], test_data['pred_sentiment'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print (confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score\n",
      "0.751195289777967\n"
     ]
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(test_data['sentiment'], test_data['pred_sentiment'])\n",
    "\n",
    "print(\"ROC AUC Score\")\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
