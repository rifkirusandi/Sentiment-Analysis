{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1210, 32)          640032    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1209, 32)          2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 643,234\n",
      "Trainable params: 643,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('UndersampledModel5\\\\tf_cnnmodel')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('data_test.csv', converters={'reviews' : str})\n",
    "# test_data.drop([\"Date\", \"Content\"], axis=1, inplace=True)\n",
    "# test_data.fillna(0)\n",
    "# test_data = test_data.fillna(\"\")\n",
    "# test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    x_test  = np.array( tokenizer.texts_to_sequences(test_data['review'].tolist()) )\n",
    "    # x_test = tokenizer\n",
    "    x_test = pad_sequences(x_test, padding='post', maxlen=1210)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "[[0.2993238  0.7255818 ]\n",
      " [0.37378752 0.62445515]\n",
      " [0.3328815  0.690081  ]\n",
      " ...\n",
      " [0.56172544 0.38212004]\n",
      " [0.64729553 0.28846192]\n",
      " [0.44660735 0.5489482 ]]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on test  data using `predict`\n",
    "print(\"Generate predictions for all samples\")\n",
    "predictions = new_model.predict(x_test)\n",
    "print(predictions)\n",
    "predict_results = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_sentiment'] = predict_results\n",
    "test_data['pred_sentiment'] = np.where((test_data.pred_sentiment == 0),'0',test_data.pred_sentiment)\n",
    "test_data['pred_sentiment'] = np.where((test_data.pred_sentiment == '1'),'1',test_data.pred_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.84      0.75       222\n",
      "           1       0.91      0.80      0.85       443\n",
      "\n",
      "    accuracy                           0.82       665\n",
      "   macro avg       0.79      0.82      0.80       665\n",
      "weighted avg       0.83      0.82      0.82       665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = ['0', '1']\n",
    "    \n",
    "print(classification_report(test_data['sentiment'].values.astype(int).astype(str),test_data['pred_sentiment'].values,labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0    1\n",
      "Actual             \n",
      "0          186   36\n",
      "1           87  356\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(test_data['sentiment'], test_data['pred_sentiment'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print (confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score\n",
      "0.820724787993411\n"
     ]
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(test_data['sentiment'], test_data['pred_sentiment'])\n",
    "\n",
    "print(\"ROC AUC Score\")\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1210) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1210), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 5).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Sentimen\n",
    "sequence20 = tokenizer.texts_to_sequences(['perfect morning walk amazing sunrise'])\n",
    "\n",
    "\n",
    "test20 = pad_sequences(sequence20, padding=\"post\")\n",
    "labels[np.around(new_model.predict(test20)).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence30 = tokenizer.texts_to_sequences(['dont recommend rubbish everywhere'])\n",
    "\n",
    "\n",
    "test30 = pad_sequences(sequence30, padding=\"post\")\n",
    "labels[np.around(new_model.predict(test30)).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
