{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1210, 32)          640032    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1209, 32)          2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 643,234\n",
      "Trainable params: 643,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('UndersampledModel5\\\\tf_cnnmodel')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>666</td>\n",
       "      <td>Jun-16</td>\n",
       "      <td>The beach very nice with a very beautiful view...</td>\n",
       "      <td>nice beautiful view alot rubish waterbut well ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.362, 'pos': 0.638, 'comp...</td>\n",
       "      <td>0.8316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>391</td>\n",
       "      <td>Dec-16</td>\n",
       "      <td>Stunning! We stayed at Holiday Inn and wandere...</td>\n",
       "      <td>stun stay holiday inn wander along buy corn sa...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.538, 'pos': 0.462, 'comp...</td>\n",
       "      <td>0.9001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>Jul-16</td>\n",
       "      <td>When it is low tide (most of the day), the bea...</td>\n",
       "      <td>low tide day disgust shallow reef barrier cant...</td>\n",
       "      <td>{'neg': 0.169, 'neu': 0.681, 'pos': 0.15, 'com...</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>645</td>\n",
       "      <td>Jan-17</td>\n",
       "      <td>Great place, great people, perfect relax. We w...</td>\n",
       "      <td>great place great people perfect relax two day...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.486, 'pos': 0.514, 'comp...</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>521</td>\n",
       "      <td>Sep-17</td>\n",
       "      <td>The best holidayss ever...rom치ntic, amazing pe...</td>\n",
       "      <td>best holiday everrom치ntic amazing people cultu...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.238, 'pos': 0.762, 'comp...</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content  \\\n",
       "666  Jun-16  The beach very nice with a very beautiful view...   \n",
       "391  Dec-16  Stunning! We stayed at Holiday Inn and wandere...   \n",
       "344  Jul-16  When it is low tide (most of the day), the bea...   \n",
       "645  Jan-17  Great place, great people, perfect relax. We w...   \n",
       "521  Sep-17  The best holidayss ever...rom치ntic, amazing pe...   \n",
       "\n",
       "                                                review  \\\n",
       "666  nice beautiful view alot rubish waterbut well ...   \n",
       "391  stun stay holiday inn wander along buy corn sa...   \n",
       "344  low tide day disgust shallow reef barrier cant...   \n",
       "645  great place great people perfect relax two day...   \n",
       "521  best holiday everrom치ntic amazing people cultu...   \n",
       "\n",
       "                                                scores  compound  sentiment  \n",
       "666  {'neg': 0.0, 'neu': 0.362, 'pos': 0.638, 'comp...    0.8316          1  \n",
       "391  {'neg': 0.0, 'neu': 0.538, 'pos': 0.462, 'comp...    0.9001          1  \n",
       "344  {'neg': 0.169, 'neu': 0.681, 'pos': 0.15, 'com...   -0.0772          0  \n",
       "645  {'neg': 0.0, 'neu': 0.486, 'pos': 0.514, 'comp...    0.9413          1  \n",
       "521  {'neg': 0.0, 'neu': 0.238, 'pos': 0.762, 'comp...    0.9595          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('nusadua_test.csv', converters={'reviews' : str})\n",
    "# test_data.drop([\"Date\", \"Content\"], axis=1, inplace=True)\n",
    "# test_data.fillna(0)\n",
    "# test_data = test_data.fillna(\"\")\n",
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    x_test  = np.array( tokenizer.texts_to_sequences(test_data['review'].tolist()) )\n",
    "    # x_test = tokenizer\n",
    "    x_test = pad_sequences(x_test, padding='post', maxlen=1210)\n",
    "except AttributeError :\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-51b6a50a4005>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# on test  data using `predict`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Generate predictions for all samples\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpredict_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on test  data using `predict`\n",
    "print(\"Generate predictions for all samples\")\n",
    "predictions = new_model.predict(x_test)\n",
    "print(predictions)\n",
    "predict_results = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_sentiment'] = predict_results\n",
    "test_data['pred_sentiment'] = np.where((test_data.pred_sentiment == 0),'0',test_data.pred_sentiment)\n",
    "test_data['pred_sentiment'] = np.where((test_data.pred_sentiment == '1'),'1',test_data.pred_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['0', '1']\n",
    "    \n",
    "print(classification_report(test_data['sentiment'].values.astype(int).astype(str),test_data['pred_sentiment'].values,labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(test_data['sentiment'], test_data['pred_sentiment'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print (confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(test_data['sentiment'], test_data['pred_sentiment'])\n",
    "\n",
    "print(\"ROC AUC Score\")\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Sentimen\n",
    "sequence20 = tokenizer.texts_to_sequences(['perfect morning walk amazing sunrise'])\n",
    "\n",
    "\n",
    "test20 = pad_sequences(sequence20, padding=\"post\")\n",
    "labels[np.around(new_model.predict(test20)).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence30 = tokenizer.texts_to_sequences(['dont recommend rubbish everywhere'])\n",
    "\n",
    "\n",
    "test30 = pad_sequences(sequence30, padding=\"post\")\n",
    "labels[np.around(new_model.predict(test30)).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
